{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "D-LpNa7WnO8P",
        "sXngvY3RB2m6",
        "IUGEv06fB9lX",
        "pzMGTvmyCOKC",
        "yjRFnLYvGztz",
        "rQKchKarHAhy",
        "tAAxpCwvI34V",
        "QvJ38UlbJUQ7",
        "zfHgsB0PMxNj",
        "1OIh41LDPyT-",
        "q6kMjU9VM2M4",
        "ajJf7RnOTd3G",
        "6gvU-EoaRLPa",
        "hiJm0yxuVP6D",
        "Yfh3krvXb15K"
      ],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOfRJIhGJlVxVuXLR3ZSBZG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5df1b3ab09884146887acb8df8ad7ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71f3beee94e344eb8c3246ee998d8ecf",
              "IPY_MODEL_de3aa4e7cb31420188688b2a6bdb31cc",
              "IPY_MODEL_8ba2455d654d4693aac51d66d14db522"
            ],
            "layout": "IPY_MODEL_3b83422f483f45e89b54aa412af8455c"
          }
        },
        "71f3beee94e344eb8c3246ee998d8ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de9dc25d61a343dbac7aeaa60645a5ce",
            "placeholder": "​",
            "style": "IPY_MODEL_d7175886dfba47aaa38796828e6a2b44",
            "value": "100%"
          }
        },
        "de3aa4e7cb31420188688b2a6bdb31cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a76dbddab4a41e08bfce217ddf0237a",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc9f1227e9a8452190449adea664f483",
            "value": 3
          }
        },
        "8ba2455d654d4693aac51d66d14db522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84192af4ce6a4b6db4a0a42bac05f287",
            "placeholder": "​",
            "style": "IPY_MODEL_c200a156f6854bd285eebfa83fd22864",
            "value": " 3/3 [00:00&lt;00:00, 56.96it/s]"
          }
        },
        "3b83422f483f45e89b54aa412af8455c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de9dc25d61a343dbac7aeaa60645a5ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7175886dfba47aaa38796828e6a2b44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a76dbddab4a41e08bfce217ddf0237a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc9f1227e9a8452190449adea664f483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84192af4ce6a4b6db4a0a42bac05f287": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c200a156f6854bd285eebfa83fd22864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h0806449f/PyTorch/blob/main/NLP_first_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **== 0. 簡介: transformer可以做什麼 ==**\n",
        "from HuggingFace"
      ],
      "metadata": {
        "id": "D-LpNa7WnO8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "yQOt9BfAjggT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 情緒分析\n",
        "classifier = pipeline(model = \"distilbert-base-uncased-finetuned-sst-2-english\", # Dfault model\n",
        "                      task = \"sentiment-analysis\")\n",
        "\n",
        "\n",
        "classifier(\"首次嘗試使用NLP相關模型, 模型來自於HuggingFace, 看起來有點厲害\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1rgzdfTj4FH",
        "outputId": "471b3dc1-ba28-46e3-9993-56cb7377238d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.970554769039154}]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 零樣本 - 文本分類\n",
        "classifier = pipeline(model = \"facebook/bart-large-mnli\", # Default model\n",
        "                      task = \"zero-shot-classification\")\n",
        "\n",
        "classifier(\"This is a course about the Transformers library\",\n",
        "           candidate_labels=[\"education\", \"politics\", \"business\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWEfGIA8l_LL",
        "outputId": "9e599e18-602c-4c57-8d87-0361eacfcca5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'This is a course about the Transformers library',\n",
              " 'labels': ['education', 'business', 'politics'],\n",
              " 'scores': [0.8445989489555359, 0.11197412759065628, 0.04342695698142052]}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 文本生成\n",
        "generator = pipeline(model = \"gpt2\", # Default model\n",
        "                     task = \"text-generation\")\n",
        "\n",
        "generator(\"These are some steps for build risk forecast model\",\n",
        "          max_new_tokens = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Yw8eATWnjok",
        "outputId": "90a0fccd-bf8f-44c3-fff6-3a50e87f6dfe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"These are some steps for build risk forecast model (SSM) and prediction system (PWS) that make the best use of this information.\\n\\n1. To forecast forecast performance based on the results of a particular investment.\\n\\nThis is a very important idea. It's what the\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 文本生成\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "\n",
        "generator(\n",
        "    \"These are some steps for build risk forecast model\",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLCJXBWKsMJF",
        "outputId": "9e06742d-0c0e-4013-ea38-d8c1d4aad921"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'These are some steps for build risk forecast model design.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'},\n",
              " {'generated_text': 'These are some steps for build risk forecast model research. For more information, visit our\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **== 1. Transformer ==**"
      ],
      "metadata": {
        "id": "6w95AXYX77De"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Pipeline"
      ],
      "metadata": {
        "id": "sXngvY3RB2m6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(model = \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "                      task = \"sentiment-analysis\")\n",
        "\n",
        "classifier(\n",
        "    [\n",
        "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "        \"I hate this so much!\",\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3gi8KyN8MCi",
        "outputId": "2a337a77-2f97-4309-b411-e883f5280a06"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598048329353333},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.1 Tokenizer"
      ],
      "metadata": {
        "id": "IUGEv06fB9lX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# 使用預訓練過的 checkpoint\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "LPukztIu8t-o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CheckTokenize\n",
        "\n",
        "raw_inputs = [\"I've been waiting for a HuggingFace course my whole life.\",\n",
        "              \"I hate this so much!\",]\n",
        "\n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\") # 將返回 dict\n",
        "\n",
        "print(inputs[\"input_ids\"])\n",
        "print(inputs[\"attention_mask\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swa9y9mh9ClX",
        "outputId": "93cf92f7-4e67-4eed-fd38-21062741f087"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
            "          2607,  2026,  2878,  2166,  1012,   102],\n",
            "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.2 Through pretrained model"
      ],
      "metadata": {
        "id": "pzMGTvmyCOKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "9ZBzL9nX9r8-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model's output\n",
        "outputs = model(**inputs)\n",
        "\n",
        "outputs.logits\n",
        "\n",
        "# 第一句, 負面情緒的機率, 正面情緒的機率\n",
        "# 第二句, 負面情緒的機率, 正面情緒的機率"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pSPLYSt_2E9",
        "outputId": "cf9e9e64-45b0-4145-c840-233a0168aeda"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.5607,  1.6123],\n",
              "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.3 Logits -> 有意義的回答"
      ],
      "metadata": {
        "id": "JxDTqvVvGd89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 情緒字典\n",
        "class_names = model.config.id2label\n",
        "\n",
        "# logits -> probs -> label_index\n",
        "probility = torch.softmax(outputs.logits, dim = 1)\n",
        "label = torch.argmax(probility, dim = 1)\n",
        "\n",
        "# 第一句\n",
        "print(f\"第一句情緒判斷:{class_names[label[0].item()]}\")\n",
        "# 第二句\n",
        "print(f\"第二句情緒判斷:{class_names[label[1].item()]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyqjG6aPDLFu",
        "outputId": "a86837cb-bd5a-4147-a3a2-8b73539d97ea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第一句情緒判斷:POSITIVE\n",
            "第二句情緒判斷:NEGATIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Model"
      ],
      "metadata": {
        "id": "yjRFnLYvGztz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.1 Get pretrained model"
      ],
      "metadata": {
        "id": "rQKchKarHAhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "# 使用此模型作者提供的 checkpoint\n",
        "model = BertModel.from_pretrained(\"bert-base-cased\")\n",
        "# [INFO] -> 如果需要客製化, 需要整定參數"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8V-LLtiHEax",
        "outputId": "09be7125-f785-416f-d0e6-8e70956757de"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.2 Save model"
      ],
      "metadata": {
        "id": "tAAxpCwvI34V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"Model_of_Bert\")\n",
        "\n",
        "# 將於指定資料夾名稱中, 儲存兩個文件\n",
        "# 1. config.json  模型屬性\n",
        "# 2. pytorch_model.bin  模型的權重"
      ],
      "metadata": {
        "id": "FaLiF0_DIycS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Tokenizer\n",
        "句子 -> 數字\n",
        "* Word-based\n",
        "* Character-based (對英文較無意義, 因為英文通常一個字就是一個意思 / 對中文意義較大)\n",
        "* Save tokenizer"
      ],
      "metadata": {
        "id": "QvJ38UlbJUQ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3.1 Word-based"
      ],
      "metadata": {
        "id": "zfHgsB0PMxNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What is we have seven days for weekend?\"\n",
        "\n",
        "tokenized_text = text.split()\n",
        "tokenized_text\n",
        "\n",
        "# 0 -> What\n",
        "# 1 -> is\n",
        "# ...\n",
        "# 8 -> unknown"
      ],
      "metadata": {
        "id": "OKSO08ktMw4p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c14ef25-2dda-4172-c30e-8485bd25beb7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What', 'is', 'we', 'have', 'seven', 'days', 'for', 'weekend?']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3.2 Pretrained tokenizer"
      ],
      "metadata": {
        "id": "1OIh41LDPyT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "# # 以下同效果\n",
        "# from transformers import AutoTokenizer\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "rcWu-NO3Px4o"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3.3 Save tokenizer"
      ],
      "metadata": {
        "id": "q6kMjU9VM2M4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(\"Toeknizer_of_Bert\")"
      ],
      "metadata": {
        "id": "FNr64V4SM2ia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b6f658-1774-44a2-880a-c174dc38bc9c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Toeknizer_of_Bert/tokenizer_config.json',\n",
              " 'Toeknizer_of_Bert/special_tokens_map.json',\n",
              " 'Toeknizer_of_Bert/vocab.txt',\n",
              " 'Toeknizer_of_Bert/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3.4 Decode"
      ],
      "metadata": {
        "id": "ajJf7RnOTd3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Today is Sunday\"\n",
        "print(f\"Original text: {text}\")\n",
        "\n",
        "token = tokenizer(text)\n",
        "print(f\"Encode text: {token['input_ids']}\")\n",
        "\n",
        "untoken = tokenizer.decode(token['input_ids'])\n",
        "print(f\"Decode token: {untoken}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gCyfyACTGhk",
        "outputId": "13483490-53bb-4d47-b143-64185bb12f18"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: Today is Sunday\n",
            "Encode text: [101, 3570, 1110, 3625, 102]\n",
            "Decode token: [CLS] Today is Sunday [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Tokenizer 如何處理多個序列"
      ],
      "metadata": {
        "id": "6gvU-EoaRLPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4.1 注意 size / shape"
      ],
      "metadata": {
        "id": "hiJm0yxuVP6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Auto 將會自動根據 checkpoint 找尋 tokenizer & model for Sequence Classification\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)                       # will return dictionary\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sequence = \"I've been waiting for a HuggingFace course my whole life.\"\n",
        "\n",
        "token = tokenizer(sequence, return_tensors=\"pt\")\n",
        "token = token[\"input_ids\"].squeeze(dim=1)                                   # add batch size\n",
        "\n",
        "model(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ1GGG8-VPoP",
        "outputId": "3871ed6d-f468-431d-f123-347074770daa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput(loss=None, logits=tensor([[-1.5607,  1.6123]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4.2 填充輸入\n",
        "1. Padding -> 如輸入有多句, 將短句子補足長度\n",
        "2. Attention mask -> 避免短句子原意受到影響, 使用 attention mask"
      ],
      "metadata": {
        "id": "Gx5h-0jdVR91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Put together"
      ],
      "metadata": {
        "id": "Yfh3krvXb15K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "sequence = [\"I've been waiting for a HuggingFace course my whole life.\", \"Nice to meet you\"]\n",
        "\n",
        "# 使用 padding 時, 會自動使用 attention mask\n",
        "padding = tokenizer(sequence, padding = \"longest\", return_tensors=\"pt\")\n",
        "print(padding)\n",
        "\n",
        "# 指定句子長度\n",
        "cutted = tokenizer(sequence, truncation = True, max_length = 4, return_tensors=\"pt\")\n",
        "print(cutted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS1NPSnyb52B",
        "outputId": "487f787a-8615-4f42-d43b-4ff0099fe417"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
            "          2607,  2026,  2878,  2166,  1012,   102],\n",
            "        [  101,  3835,  2000,  3113,  2017,   102,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
            "{'input_ids': tensor([[ 101, 1045, 1005,  102],\n",
            "        [ 101, 3835, 2000,  102]]), 'attention_mask': tensor([[1, 1, 1, 1],\n",
            "        [1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sequences = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n",
        "\n",
        "tokens = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "output = model(**tokens)"
      ],
      "metadata": {
        "id": "7MlQU99Ce8UB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 情緒字典\n",
        "class_names = model.config.id2label\n",
        "\n",
        "# logits -> probs -> label_index\n",
        "probility = torch.softmax(outputs.logits, dim = 1)\n",
        "label = torch.argmax(probility, dim = 1)\n",
        "\n",
        "# 第一句\n",
        "print(f\"第一句情緒判斷:{class_names[label[0].item()]}\")\n",
        "# 第二句\n",
        "print(f\"第二句情緒判斷:{class_names[label[1].item()]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUQ_o7kpfmU4",
        "outputId": "119d15a1-247d-434a-c298-8760dbe765a3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第一句情緒判斷:POSITIVE\n",
            "第二句情緒判斷:NEGATIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **== 2. 微調預訓練模型 ==**"
      ],
      "metadata": {
        "id": "XV04a6Y_kK_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 數據集\n",
        "from datasets import load_dataset\n",
        "\n",
        "raw_dataset = load_dataset(\"glue\", \"mrpc\")\n",
        "raw_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329,
          "referenced_widgets": [
            "5df1b3ab09884146887acb8df8ad7ad4",
            "71f3beee94e344eb8c3246ee998d8ecf",
            "de3aa4e7cb31420188688b2a6bdb31cc",
            "8ba2455d654d4693aac51d66d14db522",
            "3b83422f483f45e89b54aa412af8455c",
            "de9dc25d61a343dbac7aeaa60645a5ce",
            "d7175886dfba47aaa38796828e6a2b44",
            "6a76dbddab4a41e08bfce217ddf0237a",
            "dc9f1227e9a8452190449adea664f483",
            "84192af4ce6a4b6db4a0a42bac05f287",
            "c200a156f6854bd285eebfa83fd22864"
          ]
        },
        "id": "0BD0Wp4-n0fR",
        "outputId": "021b9d74-c648-47a8-b2b2-e7b96ba33a23"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset glue (/root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5df1b3ab09884146887acb8df8ad7ad4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 3668\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 408\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 1725\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Row 100\n",
        "raw_dataset[\"train\"][100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKudOYnis-rm",
        "outputId": "0df9ff66-f3ee-4524-c1b7-8f817a29247b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence1': 'The Nasdaq composite index inched up 1.28 , or 0.1 percent , to 1,766.60 , following a weekly win of 3.7 percent .',\n",
              " 'sentence2': 'The technology-laced Nasdaq Composite Index .IXIC was off 24.44 points , or 1.39 percent , at 1,739.87 .',\n",
              " 'label': 0,\n",
              " 'idx': 114}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}