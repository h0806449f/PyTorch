{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XOxJz4aeujSB",
        "VJCADvpo1cUR",
        "EQYMQ8ut1hD7",
        "4pnOJYw0uqKB",
        "9Yt1GRQrwRIA",
        "8WypbPcN6vWx",
        "aSjxInz1_zEH",
        "JI5qH2_lPfWI",
        "FnIvLpK2Pi-K"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPVhRS4TEPKvMciAzR02zeh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h0806449f/PyTorch/blob/main/LightningAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **== Setups ==**"
      ],
      "metadata": {
        "id": "XOxJz4aeujSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import"
      ],
      "metadata": {
        "id": "VJCADvpo1cUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "id": "u7-mzkfWz8WH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gitpython"
      ],
      "metadata": {
        "id": "g6FdX5QHFsZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning"
      ],
      "metadata": {
        "id": "LdQdycnwUsqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from git import Repo\n",
        "from PIL import Image\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "TWD9iZc_w5nf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from torchinfo import summary\n",
        "\n",
        "from lightning import LightningModule\n",
        "from lightning import Trainer"
      ],
      "metadata": {
        "id": "FnPayfqajHkm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## functions"
      ],
      "metadata": {
        "id": "EQYMQ8ut1hD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, loss_fn, optimizer, device):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    for batch, (X_train, y_train) in enumerate(dataloader):\n",
        "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "\n",
        "        train_pred = model(X_train)\n",
        "\n",
        "        loss = loss_fn(train_pred, y_train)\n",
        "        train_loss = train_loss + loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_pred_label = torch.argmax(torch.softmax(train_pred, dim = 1), dim = 1)\n",
        "        train_acc = train_acc + (train_pred_label == y_train).sum().item() / len(train_pred)\n",
        "\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    train_acc = train_acc / len(dataloader)\n",
        "\n",
        "    return train_loss, train_acc"
      ],
      "metadata": {
        "id": "bajyKhXo1lwn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, dataloader, loss_fn, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for batch, (X_test, y_test) in enumerate(dataloader):\n",
        "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "            test_pred = model(X_test)\n",
        "\n",
        "            loss = loss_fn(test_pred, y_test)\n",
        "            test_loss = test_loss + loss.item()\n",
        "\n",
        "            test_pred_label = torch.argmax(torch.softmax(test_pred, dim = 1), dim = 1)\n",
        "            test_acc = test_acc + (test_pred_label == y_test).sum().item() / len(test_pred)\n",
        "\n",
        "        test_loss = test_loss / len(dataloader)\n",
        "        test_acc = test_acc / len(dataloader)\n",
        "\n",
        "        return test_loss, test_acc"
      ],
      "metadata": {
        "id": "Yjbn7Kpk22Hr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val(model, dataloader, loss_fn, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    val_loss, val_acc = 0, 0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for batch, (X_val, y_val) in enumerate(dataloader):\n",
        "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
        "\n",
        "            val_pred = model(X_val)\n",
        "\n",
        "            loss = loss_fn(val_pred, y_val)\n",
        "            val_loss = val_loss + loss.item()\n",
        "\n",
        "            val_pred_label = torch.argmax(torch.softmax(val_pred, dim = 1), dim = 1)\n",
        "            val_acc = val_acc + (val_pred_label == y_val).sum().item() / len(val_pred)\n",
        "\n",
        "        val_loss = val_loss / len(dataloader)\n",
        "        val_acc = val_acc / len(dataloader)\n",
        "\n",
        "        return val_loss, val_acc"
      ],
      "metadata": {
        "id": "UvE1zdGh4LtA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_loop(model, train_dataloader, test_dataloader, loss_fn, optimizer, epochs, device):\n",
        "    results = {\"train_loss\":[], \"train_acc\":[], \"val_loss\":[], \"val_acc\":[]}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss, train_acc = train(model = model,\n",
        "                                      dataloader = train_dataloader,\n",
        "                                      loss_fn = loss_fn,\n",
        "                                      optimizer = optimizer,\n",
        "                                      device = device)\n",
        "\n",
        "        val_loss, val_acc = val(model = model,\n",
        "                                dataloader = val_dataloader,\n",
        "                                loss_fn = loss_fn,\n",
        "                                device = device)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}\\n\"\n",
        "              f\"Train loss: {train_loss:.4f} | Train acc: {(train_acc*100):.2f}%\\n\"\n",
        "              f\"Val loss: {val_loss:.4f} | Val acc: {(val_acc*100):.2f}%\"\n",
        "              )\n",
        "\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"val_loss\"].append(val_loss)\n",
        "        results[\"val_acc\"].append(val_acc)\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "PJhFV6sa4vcg"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **== MNIST ==**"
      ],
      "metadata": {
        "id": "4pnOJYw0uqKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process"
      ],
      "metadata": {
        "id": "9Yt1GRQrwRIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "transform\n"
      ],
      "metadata": {
        "id": "oETEcR_iuWWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = 0.5, std = 0.5)\n",
        "])"
      ],
      "metadata": {
        "id": "I4o7VX6Wr68Z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "sBBBb3uewJDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST(\n",
        "    root = \"./data/mnist\",\n",
        "    train = True,\n",
        "    transform = transform,\n",
        "    download = True)\n",
        "\n",
        "test_dataset = datasets.MNIST(\n",
        "    root = \"./data/mnist\",\n",
        "    train = False,\n",
        "    transform = transform,\n",
        "    download = True)"
      ],
      "metadata": {
        "id": "_RtX4zxYtSvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "split dataset"
      ],
      "metadata": {
        "id": "rOxzaNaawME6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset = random_split(train_dataset,\n",
        "                                          lengths=[50000, 10000])"
      ],
      "metadata": {
        "id": "aQQu3Km9u41F"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset), len(val_dataset), len(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzgbvPTDvhd6",
        "outputId": "2921946a-0b0f-413d-cf31-6cc4e9b13ff8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataloader"
      ],
      "metadata": {
        "id": "UV_Sv5GFwOdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset,\n",
        "                              batch_size = 32,\n",
        "                              shuffle = True,\n",
        "                              drop_last = True)\n",
        "\n",
        "val_dataloader = DataLoader(val_dataset,\n",
        "                            batch_size = 32,\n",
        "                            shuffle = False,\n",
        "                            drop_last = True)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset,\n",
        "                             batch_size = 32,\n",
        "                             shuffle = False,\n",
        "                             drop_last = True)"
      ],
      "metadata": {
        "id": "coTde45fv9qc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check dataloader distribution"
      ],
      "metadata": {
        "id": "jCwZH9NAxe8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_counter = Counter()\n",
        "\n",
        "# for imgs, labels in train_dataloader:\n",
        "#     train_counter.update(labels.tolist())\n",
        "\n",
        "# print(\"Training label distribution:\")\n",
        "# print(sorted(train_counter.items()))"
      ],
      "metadata": {
        "id": "W4ZU0K6zwk8U"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f\"{imgs.shape} -> batch_szie, channel, height, width\")"
      ],
      "metadata": {
        "id": "Gb4yiTW7xngH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MNIST_model_1(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.flat = nn.Flatten()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(num_features, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = 0.2),\n",
        "            nn.Linear(128, 32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = 0.2),\n",
        "            nn.Linear(32, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flat(x)\n",
        "        x = self.layers(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "MNIST_model_1 = MNIST_model_1(num_features = 1*28*28, num_classes = 10)"
      ],
      "metadata": {
        "id": "6IyawLVxzjdv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and results"
      ],
      "metadata": {
        "id": "8WypbPcN6vWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(MNIST_model_1.parameters(),\n",
        "                             lr = 0.001)\n",
        "\n",
        "MNIST_model_1_results = train_test_loop(model = MNIST_model_1,\n",
        "                                        train_dataloader = train_dataloader,\n",
        "                                        test_dataloader = val_dataloader,\n",
        "                                        loss_fn = loss_fn,\n",
        "                                        optimizer = optimizer,\n",
        "                                        epochs = 10,\n",
        "                                        device = device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luexOJj81U3A",
        "outputId": "e6eb31b2-6354-4a03-ebd6-0cfe2851a974"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Train loss: 0.4407 | Train acc: 88.78%\n",
            "Val loss: 0.1466 | Val acc: 95.54%\n",
            "Epoch: 2\n",
            "Train loss: 0.2284 | Train acc: 93.19%\n",
            "Val loss: 0.1040 | Val acc: 96.64%\n",
            "Epoch: 3\n",
            "Train loss: 0.1847 | Train acc: 94.43%\n",
            "Val loss: 0.0984 | Val acc: 96.99%\n",
            "Epoch: 4\n",
            "Train loss: 0.1661 | Train acc: 94.90%\n",
            "Val loss: 0.0889 | Val acc: 97.04%\n",
            "Epoch: 5\n",
            "Train loss: 0.1465 | Train acc: 95.56%\n",
            "Val loss: 0.0813 | Val acc: 97.37%\n",
            "Epoch: 6\n",
            "Train loss: 0.1430 | Train acc: 95.64%\n",
            "Val loss: 0.0808 | Val acc: 97.45%\n",
            "Epoch: 7\n",
            "Train loss: 0.1313 | Train acc: 95.98%\n",
            "Val loss: 0.0788 | Val acc: 97.53%\n",
            "Epoch: 8\n",
            "Train loss: 0.1236 | Train acc: 96.20%\n",
            "Val loss: 0.0750 | Val acc: 97.62%\n",
            "Epoch: 9\n",
            "Train loss: 0.1198 | Train acc: 96.29%\n",
            "Val loss: 0.0730 | Val acc: 97.63%\n",
            "Epoch: 10\n",
            "Train loss: 0.1143 | Train acc: 96.45%\n",
            "Val loss: 0.0723 | Val acc: 97.68%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_1, test_acc_1 = test(model = MNIST_model_1,\n",
        "                           dataloader = test_dataloader,\n",
        "                           loss_fn = loss_fn,\n",
        "                           device = device)\n",
        "print(f\"Test loss: {test_loss_1:.4f} | Test acc: {(test_acc_1*100):.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Y2mTOWh_J24",
        "outputId": "379acba3-4776-473f-9489-41dd96b30a80"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.0697 | Test acc: 97.87%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **== Custom dataset, dataloader ==**"
      ],
      "metadata": {
        "id": "aSjxInz1_zEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "function"
      ],
      "metadata": {
        "id": "7xfzQwkCOLnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class CustomDataset(Dataset):\n",
        "#     # Set up attributes\n",
        "#     def __init__(self, csv_path, img_dir, transform = None):\n",
        "#         df = pd.read_csv(csv_path)\n",
        "#         self.img_dir = img_dir\n",
        "#         self.transform = transform\n",
        "\n",
        "#         self.img_names = df[\"filepath\"]\n",
        "#         self.labels = df[\"label\"]\n",
        "\n",
        "#     # Define how to get single record\n",
        "#     def __getitem__(self, index):\n",
        "#         img = Image.open(os.path.join(self.img_dir, self.img_names[index]))\n",
        "\n",
        "#         if self.transform is not None:\n",
        "#             img = self.transform(img)\n",
        "\n",
        "#         label = self.labels[index]\n",
        "\n",
        "#         return img, label\n",
        "\n",
        "#     # Return the length of dataset\n",
        "#     def __len__(self):\n",
        "#         return self.labels.shape[0]"
      ],
      "metadata": {
        "id": "Y_SGtM4-BJ8P"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "raw dara -> pandas df"
      ],
      "metadata": {
        "id": "EKXgqP8hONig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Download\n",
        "# if not os.path.exists(\"mnist-pngs\"):\n",
        "#     Repo.clone_from(\"https://github.com/rasbt/mnist-pngs\", \"mnist-pngs\")\n",
        "\n",
        "# # Read csv\n",
        "# df_train = pd.read_csv(\"mnist-pngs/train.csv\")\n",
        "# df_test = pd.read_csv(\"mnist-pngs/test.csv\")\n",
        "\n",
        "# # 順序打亂 (為了使val dataset 也包含多樣資料)\n",
        "# df_train = df_train.sample(frac = 1, random_state = 123)\n",
        "\n",
        "# # Split train & val dataset\n",
        "# split_index = round(df_train.shape[0] * 0.9)\n",
        "\n",
        "# df_new_train = df_train.iloc[:split_index]\n",
        "# df_new_val = df_train.iloc[split_index:]\n",
        "\n",
        "# df_new_train.to_csv(\"mnist-pngs/new_train.csv\", index=None)\n",
        "# df_new_val.to_csv(\"mnist-pngs/new_val.csv\", index=None)"
      ],
      "metadata": {
        "id": "gZgufRGRF2IZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "transform"
      ],
      "metadata": {
        "id": "LSA0ACAIOSIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data_transforms = {\n",
        "#     \"train\": transforms.Compose([\n",
        "#         transforms.Resize(32),\n",
        "#         transforms.RandomCrop((28, 28)),\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize(mean = 0.5, std = 0.5)\n",
        "#     ]),\n",
        "#     \"test\": transforms.Compose([\n",
        "#         transforms.Resize(32),\n",
        "#         transforms.CenterCrop((28, 28)),\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize(mean = 0.5, std = 0.5)\n",
        "#     ])\n",
        "# }"
      ],
      "metadata": {
        "id": "WoNPALl9MXKH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset -> dataloader"
      ],
      "metadata": {
        "id": "AiQRyJTxOUD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset = CustomDataset(\n",
        "#     csv_path = \"mnist-pngs/new_train.csv\",\n",
        "#     img_dir = \"mnist-pngs/\",\n",
        "#     transform = data_transforms[\"train\"])\n",
        "\n",
        "# train_dataloader = DataLoader(\n",
        "#     dataset = train_dataset,\n",
        "#     batch_size = 32,\n",
        "#     shuffle = True)"
      ],
      "metadata": {
        "id": "KPCEoxk4NXF6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **== CNN -> regression dataset ==**"
      ],
      "metadata": {
        "id": "JI5qH2_lPfWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normal CNN\n",
        "\"\"\"\n",
        "    input\n",
        "    hidden layers\n",
        "    softmax\n",
        "    argmax\n",
        "    output layers: number of class names\n",
        "\"\"\"\n",
        "\n",
        "# regression\n",
        "\"\"\"\n",
        "    input\n",
        "    hidden layers\n",
        "    output layers: 1\n",
        "    loss_fn -> Meas Squared Error -> nn.MSELoss()\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "jrx2QWksQYyr",
        "outputId": "36e4e9c8-219b-4d11-bb40-2f58f6d5471f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    input\\n    hidden layers\\n    output layers: 1\\n    loss_fn -> Meas Squared Error -> nn.MSELoss()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **== CNN -> CIFAR10 ==**"
      ],
      "metadata": {
        "id": "FnIvLpK2Pi-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process"
      ],
      "metadata": {
        "id": "7eaCmhyj68ZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "transforms"
      ],
      "metadata": {
        "id": "fSpAnboLbs-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torchvision.models.ResNet18_Weights.DEFAULT\n",
        "\n",
        "transform = weights.transforms()"
      ],
      "metadata": {
        "id": "cSQdqiRtbegE"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "_OdnNV4ubzCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(root = \"./data\",\n",
        "                                             train = True,\n",
        "                                             download = True,\n",
        "                                             transform = transform)\n",
        "\n",
        "val_dataset = torchvision.datasets.CIFAR10(root = \"./data\",\n",
        "                                             train = False,\n",
        "                                             download = True,\n",
        "                                             transform = transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root = \"./data\",\n",
        "                                            train = False,\n",
        "                                            download = True,\n",
        "                                            transform = transform)"
      ],
      "metadata": {
        "id": "vemIZbrObvQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataloader"
      ],
      "metadata": {
        "id": "cBwvZL85craS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_dataloader = DataLoader(dataset = train_dataset,\n",
        "                              batch_size = BATCH_SIZE,\n",
        "                              shuffle = True,\n",
        "                              drop_last = True)\n",
        "\n",
        "val_dataloader = DataLoader(dataset = val_dataset,\n",
        "                            batch_size = BATCH_SIZE,\n",
        "                            shuffle = False,\n",
        "                            drop_last = False)\n",
        "\n",
        "test_dataloader = DataLoader(dataset = test_dataset,\n",
        "                             batch_size = BATCH_SIZE,\n",
        "                             shuffle = False,\n",
        "                             drop_last = False)"
      ],
      "metadata": {
        "id": "i0v2r-fNcsma"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "A9j7pK86d7dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torchvision.models.ResNet18_Weights.DEFAULT\n",
        "\n",
        "CIFAR10_model1 = torchvision.models.resnet18(weights = weights)"
      ],
      "metadata": {
        "id": "1Q2wtocyaqc5"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in CIFAR10_model1.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "zXkrbu5Ld50H"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CIFAR10_model1_classifier = nn.Sequential(\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p = 0.3),\n",
        "    nn.Linear(1000, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p = 0.2),\n",
        "    nn.Linear(128, 10)\n",
        "\n",
        ")\n",
        "\n",
        "CIFAR10_model1 = nn.Sequential(\n",
        "    CIFAR10_model1,\n",
        "    CIFAR10_model1_classifier\n",
        ")"
      ],
      "metadata": {
        "id": "WERvB9EAhU5B"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(CIFAR10_model1,\n",
        "        input_size = (1, 3, 32, 32),\n",
        "        col_names = [\"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width = 17)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe-zs_X_dfLn",
        "outputId": "c7be8ee1-a1f8-42e8-9251-d3249708b13d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "================================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape      Param #           Trainable\n",
              "================================================================================================\n",
              "Sequential                                    [1, 10]           --                Partial\n",
              "├─ResNet: 1-1                                 [1, 1000]         --                False\n",
              "│    └─Conv2d: 2-1                            [1, 64, 16, 16]   (9,408)           False\n",
              "│    └─BatchNorm2d: 2-2                       [1, 64, 16, 16]   (128)             False\n",
              "│    └─ReLU: 2-3                              [1, 64, 16, 16]   --                --\n",
              "│    └─MaxPool2d: 2-4                         [1, 64, 8, 8]     --                --\n",
              "│    └─Sequential: 2-5                        [1, 64, 8, 8]     --                False\n",
              "│    │    └─BasicBlock: 3-1                   [1, 64, 8, 8]     (73,984)          False\n",
              "│    │    └─BasicBlock: 3-2                   [1, 64, 8, 8]     (73,984)          False\n",
              "│    └─Sequential: 2-6                        [1, 128, 4, 4]    --                False\n",
              "│    │    └─BasicBlock: 3-3                   [1, 128, 4, 4]    (230,144)         False\n",
              "│    │    └─BasicBlock: 3-4                   [1, 128, 4, 4]    (295,424)         False\n",
              "│    └─Sequential: 2-7                        [1, 256, 2, 2]    --                False\n",
              "│    │    └─BasicBlock: 3-5                   [1, 256, 2, 2]    (919,040)         False\n",
              "│    │    └─BasicBlock: 3-6                   [1, 256, 2, 2]    (1,180,672)       False\n",
              "│    └─Sequential: 2-8                        [1, 512, 1, 1]    --                False\n",
              "│    │    └─BasicBlock: 3-7                   [1, 512, 1, 1]    (3,673,088)       False\n",
              "│    │    └─BasicBlock: 3-8                   [1, 512, 1, 1]    (4,720,640)       False\n",
              "│    └─AdaptiveAvgPool2d: 2-9                 [1, 512, 1, 1]    --                --\n",
              "│    └─Linear: 2-10                           [1, 1000]         (513,000)         False\n",
              "├─Sequential: 1-2                             [1, 10]           --                True\n",
              "│    └─ReLU: 2-11                             [1, 1000]         --                --\n",
              "│    └─Dropout: 2-12                          [1, 1000]         --                --\n",
              "│    └─Linear: 2-13                           [1, 128]          128,128           True\n",
              "│    └─ReLU: 2-14                             [1, 128]          --                --\n",
              "│    └─Dropout: 2-15                          [1, 128]          --                --\n",
              "│    └─Linear: 2-16                           [1, 10]           1,290             True\n",
              "================================================================================================\n",
              "Total params: 11,818,930\n",
              "Trainable params: 129,418\n",
              "Non-trainable params: 11,689,512\n",
              "Total mult-adds (M): 37.66\n",
              "================================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 0.82\n",
              "Params size (MB): 47.28\n",
              "Estimated Total Size (MB): 48.11\n",
              "================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and results\n",
        "took 40 mins"
      ],
      "metadata": {
        "id": "8KNJMAN16_6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(CIFAR10_model1.parameters(),\n",
        "                             lr = 0.001)"
      ],
      "metadata": {
        "id": "DQHjl42YeMSK"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_CIFAR10_model1 = train_val_loop(model = CIFAR10_model1,\n",
        "                                        train_dataloader = train_dataloader,\n",
        "                                        test_dataloader = val_dataloader,\n",
        "                                        loss_fn = loss_fn,\n",
        "                                        optimizer = optimizer,\n",
        "                                        epochs = 10,\n",
        "                                        device = device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-HbGTXlee6p",
        "outputId": "c105c581-60a0-45d9-9943-b233c6969104"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Train loss: 1.1980 | Train acc: 59.01%\n",
            "Val loss: 0.8663 | Val acc: 69.91%\n",
            "Epoch: 2\n",
            "Train loss: 1.1302 | Train acc: 61.27%\n",
            "Val loss: 0.8134 | Val acc: 72.18%\n",
            "Epoch: 3\n",
            "Train loss: 1.1144 | Train acc: 62.28%\n",
            "Val loss: 0.7918 | Val acc: 73.07%\n",
            "Epoch: 4\n",
            "Train loss: 1.1039 | Train acc: 62.43%\n",
            "Val loss: 0.8165 | Val acc: 72.14%\n",
            "Epoch: 5\n",
            "Train loss: 1.0965 | Train acc: 63.17%\n",
            "Val loss: 0.8029 | Val acc: 72.89%\n",
            "Epoch: 6\n",
            "Train loss: 1.0949 | Train acc: 63.39%\n",
            "Val loss: 0.7946 | Val acc: 72.79%\n",
            "Epoch: 7\n",
            "Train loss: 1.0892 | Train acc: 63.37%\n",
            "Val loss: 0.8187 | Val acc: 72.32%\n",
            "Epoch: 8\n",
            "Train loss: 1.0890 | Train acc: 63.62%\n",
            "Val loss: 0.8098 | Val acc: 72.02%\n",
            "Epoch: 9\n",
            "Train loss: 1.0890 | Train acc: 63.35%\n",
            "Val loss: 0.8044 | Val acc: 73.02%\n",
            "Epoch: 10\n",
            "Train loss: 1.0880 | Train acc: 63.31%\n",
            "Val loss: 0.7658 | Val acc: 73.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_2, test_acc_2 = test(model = CIFAR10_model1,\n",
        "                               dataloader = test_dataloader,\n",
        "                               loss_fn = loss_fn,\n",
        "                               device = device)\n",
        "\n",
        "print(f\"Test loss: {test_loss_2:.4f} | Test acc: {(test_acc_2*100):.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFx8MmWf6bXK",
        "outputId": "078538f2-513f-4d1a-e222-3024114ba90d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.7658 | Test acc: 73.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save, load, predict"
      ],
      "metadata": {
        "id": "L8dvEpxV0NjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "save model"
      ],
      "metadata": {
        "id": "lvM5vAp8thBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(CIFAR10_model1, \"./data/mode_1forCIFAR10.pt\")"
      ],
      "metadata": {
        "id": "Av6hJ0Qyth9D"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load model"
      ],
      "metadata": {
        "id": "CXSdua6U0KPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(\"/content/data/mode_1forCIFAR10.pt\")"
      ],
      "metadata": {
        "id": "Kar-_yUg0GgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "predict"
      ],
      "metadata": {
        "id": "gI_4Hrx50Lex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.eval()\n",
        "\n",
        "image, label = next(iter(test_dataset))\n",
        "image = image.unsqueeze(dim = 0).to(device)\n",
        "\n",
        "logits = model(image)\n",
        "pred_probality = torch.softmax(logits, dim = 1)\n",
        "pred_label = torch.argmax(pred_probality, dim = 1).item()\n",
        "\n",
        "print(f\"Predict label: {pred_label} | Actual label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWjblXtAuAOv",
        "outputId": "909fea1e-4576-403e-c078-983f9a00c8de"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict label: 3 | Actual label: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **== ViT -> image ==**"
      ],
      "metadata": {
        "id": "zRCacUwuPjYu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2KWiQbW-1SmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **== temp ==**"
      ],
      "metadata": {
        "id": "agAZmgCwPjxe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **==temp==**"
      ],
      "metadata": {
        "id": "WGwjpYxL1yRK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **==temp==**"
      ],
      "metadata": {
        "id": "n5QJxIUV10oO"
      }
    }
  ]
}