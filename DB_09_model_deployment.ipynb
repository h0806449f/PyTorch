{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOm3nEoT+HrTXITSlbParZw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h0806449f/PyTorch/blob/main/DB_09_model_deployment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **== Functions and setups ==**"
      ],
      "metadata": {
        "id": "lfkmskPeBaDk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setups"
      ],
      "metadata": {
        "id": "h0xW9v6lETlH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOGJPHxv6v8O"
      },
      "outputs": [],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchinfo import summary"
      ],
      "metadata": {
        "id": "4IbxfGPNBqxm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "PDesjwAGJAEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train -> train_loss, train_acc\n",
        "def train(model, dataloader, loss_fn, optimizer, device):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    for batch, (X_train, y_train) in enumerate(dataloader):\n",
        "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "\n",
        "        train_preds = model(X_train)\n",
        "\n",
        "        loss = loss_fn(train_preds, y_train)\n",
        "        train_loss = train_loss + loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_preds_label = torch.argmax(torch.softmax(train_preds, dim = 1), dim = 1)\n",
        "        train_acc = train_acc + (train_preds_label == y_train).sum().item() / len(train_preds)\n",
        "\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    train_acc = train_acc / len(dataloader)\n",
        "\n",
        "    return train_loss, train_acc"
      ],
      "metadata": {
        "id": "H9tTSypvCtRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test -> test_loss, test_acc\n",
        "def test(model, dataloader, loss_fn, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for batch, (X_test, y_test) in enumerate(dataloader):\n",
        "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "            test_preds = model(X_test)\n",
        "\n",
        "            loss = loss_fn(test_preds, y_test)\n",
        "            test_loss = test_loss + loss.item()\n",
        "\n",
        "            test_preds_label = torch.argmax(torch.softmax(test_preds, dim = 1), dim = 1)\n",
        "            test_acc = test_acc + (test_preds_label == y_test).sum().item() / len(test_preds)\n",
        "\n",
        "        test_loss = test_loss / len(dataloader)\n",
        "        test_acc = test_acc / len(dataloader)\n",
        "\n",
        "        return test_loss, test_acc"
      ],
      "metadata": {
        "id": "JPSa75CsCuen"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_test_loop -> results dictionary\n",
        "def train_test_loop(model, train_dataloader, test_dataloader, loss_fn, optimizer, epochs, device):\n",
        "    results = {\"train_loss\":[], \"train_acc\":[], \"test_loss\":[], \"test_acc\":[]}\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train(model = model, dataloader = train_dataloader, loss_fn = loss_fn, optimizer = optimizer, device = device)\n",
        "        test_loss, test_acc = test(model = model, dataloader = test_dataloader, loss_fn = loss_fn, device = device)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}\\n\"\n",
        "              f\"Train Loss: {train_loss:.4f} | Train Accuracy: {(train_acc*100):.2f}%\\n\"\n",
        "              f\"Test Loss: {test_loss:.4f} | Train Accuracy: {(test_acc*100):.2f}%\")\n",
        "\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    return results\n",
        "\n",
        "    # plt.figure(figsize = (6, 3))\n",
        "    # plt.subplot(1, 2, 1)\n",
        "    # plt.plot(results[\"train_loss\"], label = \"Train Loss\")\n",
        "    # plt.plot(results[\"test_loss\"], label = \"Test Loss\")\n",
        "    # plt.subplot(1, 2, 2)\n",
        "    # plt.plot(results[\"train_acc\"], label = \"Train Accuracy\")\n",
        "    # plt.plot(results[\"test_acc\"], label = \"Test Accuracy\")"
      ],
      "metadata": {
        "id": "kapNg2EnCv24"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **== Dataset and dataloader ==**"
      ],
      "metadata": {
        "id": "N1sSAjLNLIZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Raw data"
      ],
      "metadata": {
        "id": "WTH_ZsHDV9C_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = Path(\"data/\")\n",
        "image_dir = data_dir / \"pizza_steak_sushi\"\n",
        "\n",
        "if image_dir.is_dir():\n",
        "    print(f\"[INFO] {image_dir} already exists\")\n",
        "else:\n",
        "    image_dir.mkdir(parents = True, exist_ok = True)\n",
        "    print(f\"[INFO] {image_dir} creating\")\n",
        "\n",
        "    with open(data_dir / \"DB_image.zip\", \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "        print(f\"[INFO] zip file downloading\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    with zipfile.ZipFile(data_dir / \"DB_image.zip\", \"r\") as zip_f:\n",
        "        print(f\"[INFO] zip file unzipping\")\n",
        "        zip_f.extractall(image_dir)\n",
        "\n",
        "    zip_file_path = data_dir / \"DB_image.zip\"\n",
        "    if zip_file_path.exists():\n",
        "        print(f\"[INFO] zip file removing\")\n",
        "        os.remove(zip_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-WxFxk9MS6Q",
        "outputId": "bd128fdd-5528-461b-d2b1-19bd70b88148"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] data/pizza_steak_sushi creating\n",
            "[INFO] zip file downloading\n",
            "[INFO] zip file unzipping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader"
      ],
      "metadata": {
        "id": "069_yXjUWAb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 目標比較: efficientnet VS vision transformer\n",
        "train_dir = image_dir / \"train\"\n",
        "test_dir = image_dir / \"test\"\n",
        "\n",
        "# Weights\n",
        "effnet_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "effnet_transforms = effnet_weights.transforms()\n",
        "\n",
        "# Dataset\n",
        "effnet_train_dataset = datasets.ImageFolder(root = train_dir, transform = effnet_transforms)\n",
        "effnet_test_dataset = datasets.ImageFolder(root = test_dir, transform = effnet_transforms)\n",
        "\n",
        "# Dataloader\n",
        "effnet_train_dataloader = DataLoader(dataset = effnet_train_dataset, batch_size = 32, shuffle = True, drop_last = True)\n",
        "effnet_test_dataloader = DataLoader(dataset = effnet_test_dataset, batch_size = 32, shuffle = False, drop_last = True)"
      ],
      "metadata": {
        "id": "Uw8JNA7xQkD0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Weights\n",
        "vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
        "vit_tranforms = vit_weights.transforms()\n",
        "\n",
        "# Dataset\n",
        "vit_train_dataset = datasets.ImageFolder(root = train_dir, transform = vit_tranforms)\n",
        "vit_test_dataset = datasets.ImageFolder(root = test_dir, transform = vit_tranforms)\n",
        "\n",
        "# Dataloader\n",
        "vit_train_dataloader = DataLoader(dataset = vit_train_dataset, batch_size = 32, shuffle = True, drop_last = True)\n",
        "vit_test_dataloader = DataLoader(dataset = vit_test_dataset, batch_size = 32, shuffle = False, drop_last = True)"
      ],
      "metadata": {
        "id": "V8Ep-7LZUrTC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model and train model"
      ],
      "metadata": {
        "id": "Y1FoXOGWWB9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Effnet"
      ],
      "metadata": {
        "id": "quZIA5snWaiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "effnet_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "\n",
        "effnet_model = torchvision.models.efficientnet_b2(weights = effnet_weights)"
      ],
      "metadata": {
        "id": "M2OXDW3JWgJ6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in effnet_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "m7YynZqCY9xt"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnet_model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p = 0.3),\n",
        "    torch.nn.Linear(in_features = 1408, out_features = 256),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Dropout(p = 0.3),\n",
        "    torch.nn.Linear(in_features = 256, out_features = 64),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Dropout(p = 0.3),\n",
        "    torch.nn.Linear(in_features = 64, out_features = 3)\n",
        ")"
      ],
      "metadata": {
        "id": "GnUe1_bpW-ZV"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(effnet_model,\n",
        "        input_size = (32, 3, 224, 224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width = 17)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ctmh711vYTkH",
        "outputId": "b0a38a01-5dac-4cef-8e6a-9967144dd6b7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===========================================================================================================================\n",
              "Layer (type:depth-idx)                                  Input Shape       Output Shape      Param #           Trainable\n",
              "===========================================================================================================================\n",
              "EfficientNet                                            [32, 3, 224, 224] [32, 3]           --                Partial\n",
              "├─Sequential: 1-1                                       [32, 3, 224, 224] [32, 1408, 7, 7]  --                False\n",
              "│    └─Conv2dNormActivation: 2-1                        [32, 3, 224, 224] [32, 32, 112, 112] --                False\n",
              "│    │    └─Conv2d: 3-1                                 [32, 3, 224, 224] [32, 32, 112, 112] (864)             False\n",
              "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112] [32, 32, 112, 112] (64)              False\n",
              "│    │    └─SiLU: 3-3                                   [32, 32, 112, 112] [32, 32, 112, 112] --                --\n",
              "│    └─Sequential: 2-2                                  [32, 32, 112, 112] [32, 16, 112, 112] --                False\n",
              "│    │    └─MBConv: 3-4                                 [32, 32, 112, 112] [32, 16, 112, 112] (1,448)           False\n",
              "│    │    └─MBConv: 3-5                                 [32, 16, 112, 112] [32, 16, 112, 112] (612)             False\n",
              "│    └─Sequential: 2-3                                  [32, 16, 112, 112] [32, 24, 56, 56]  --                False\n",
              "│    │    └─MBConv: 3-6                                 [32, 16, 112, 112] [32, 24, 56, 56]  (6,004)           False\n",
              "│    │    └─MBConv: 3-7                                 [32, 24, 56, 56]  [32, 24, 56, 56]  (10,710)          False\n",
              "│    │    └─MBConv: 3-8                                 [32, 24, 56, 56]  [32, 24, 56, 56]  (10,710)          False\n",
              "│    └─Sequential: 2-4                                  [32, 24, 56, 56]  [32, 48, 28, 28]  --                False\n",
              "│    │    └─MBConv: 3-9                                 [32, 24, 56, 56]  [32, 48, 28, 28]  (16,518)          False\n",
              "│    │    └─MBConv: 3-10                                [32, 48, 28, 28]  [32, 48, 28, 28]  (43,308)          False\n",
              "│    │    └─MBConv: 3-11                                [32, 48, 28, 28]  [32, 48, 28, 28]  (43,308)          False\n",
              "│    └─Sequential: 2-5                                  [32, 48, 28, 28]  [32, 88, 14, 14]  --                False\n",
              "│    │    └─MBConv: 3-12                                [32, 48, 28, 28]  [32, 88, 14, 14]  (50,300)          False\n",
              "│    │    └─MBConv: 3-13                                [32, 88, 14, 14]  [32, 88, 14, 14]  (123,750)         False\n",
              "│    │    └─MBConv: 3-14                                [32, 88, 14, 14]  [32, 88, 14, 14]  (123,750)         False\n",
              "│    │    └─MBConv: 3-15                                [32, 88, 14, 14]  [32, 88, 14, 14]  (123,750)         False\n",
              "│    └─Sequential: 2-6                                  [32, 88, 14, 14]  [32, 120, 14, 14] --                False\n",
              "│    │    └─MBConv: 3-16                                [32, 88, 14, 14]  [32, 120, 14, 14] (149,158)         False\n",
              "│    │    └─MBConv: 3-17                                [32, 120, 14, 14] [32, 120, 14, 14] (237,870)         False\n",
              "│    │    └─MBConv: 3-18                                [32, 120, 14, 14] [32, 120, 14, 14] (237,870)         False\n",
              "│    │    └─MBConv: 3-19                                [32, 120, 14, 14] [32, 120, 14, 14] (237,870)         False\n",
              "│    └─Sequential: 2-7                                  [32, 120, 14, 14] [32, 208, 7, 7]   --                False\n",
              "│    │    └─MBConv: 3-20                                [32, 120, 14, 14] [32, 208, 7, 7]   (301,406)         False\n",
              "│    │    └─MBConv: 3-21                                [32, 208, 7, 7]   [32, 208, 7, 7]   (686,868)         False\n",
              "│    │    └─MBConv: 3-22                                [32, 208, 7, 7]   [32, 208, 7, 7]   (686,868)         False\n",
              "│    │    └─MBConv: 3-23                                [32, 208, 7, 7]   [32, 208, 7, 7]   (686,868)         False\n",
              "│    │    └─MBConv: 3-24                                [32, 208, 7, 7]   [32, 208, 7, 7]   (686,868)         False\n",
              "│    └─Sequential: 2-8                                  [32, 208, 7, 7]   [32, 352, 7, 7]   --                False\n",
              "│    │    └─MBConv: 3-25                                [32, 208, 7, 7]   [32, 352, 7, 7]   (846,900)         False\n",
              "│    │    └─MBConv: 3-26                                [32, 352, 7, 7]   [32, 352, 7, 7]   (1,888,920)       False\n",
              "│    └─Conv2dNormActivation: 2-9                        [32, 352, 7, 7]   [32, 1408, 7, 7]  --                False\n",
              "│    │    └─Conv2d: 3-27                                [32, 352, 7, 7]   [32, 1408, 7, 7]  (495,616)         False\n",
              "│    │    └─BatchNorm2d: 3-28                           [32, 1408, 7, 7]  [32, 1408, 7, 7]  (2,816)           False\n",
              "│    │    └─SiLU: 3-29                                  [32, 1408, 7, 7]  [32, 1408, 7, 7]  --                --\n",
              "├─AdaptiveAvgPool2d: 1-2                                [32, 1408, 7, 7]  [32, 1408, 1, 1]  --                --\n",
              "├─Sequential: 1-3                                       [32, 1408]        [32, 3]           --                True\n",
              "│    └─Dropout: 2-10                                    [32, 1408]        [32, 1408]        --                --\n",
              "│    └─Linear: 2-11                                     [32, 1408]        [32, 256]         360,704           True\n",
              "│    └─ReLU: 2-12                                       [32, 256]         [32, 256]         --                --\n",
              "│    └─Dropout: 2-13                                    [32, 256]         [32, 256]         --                --\n",
              "│    └─Linear: 2-14                                     [32, 256]         [32, 64]          16,448            True\n",
              "│    └─ReLU: 2-15                                       [32, 64]          [32, 64]          --                --\n",
              "│    └─Dropout: 2-16                                    [32, 64]          [32, 64]          --                --\n",
              "│    └─Linear: 2-17                                     [32, 64]          [32, 3]           195               True\n",
              "===========================================================================================================================\n",
              "Total params: 8,078,341\n",
              "Trainable params: 377,347\n",
              "Non-trainable params: 7,700,994\n",
              "Total mult-adds (G): 21.06\n",
              "===========================================================================================================================\n",
              "Input size (MB): 19.27\n",
              "Forward/backward pass size (MB): 5017.61\n",
              "Params size (MB): 32.31\n",
              "Estimated Total Size (MB): 5069.19\n",
              "==========================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vit"
      ],
      "metadata": {
        "id": "ObS4Yx8tWdYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
        "\n",
        "vit_model = torchvision.models.vit_b_16(weights = vit_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoAA-6XwWgsj",
        "outputId": "79e8bfe0-69f6-4341-c068-0c5849a662bd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
            "100%|██████████| 330M/330M [00:03<00:00, 107MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in vit_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "xVoOgnh8ZBf9"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_model.heads = torch.nn.Sequential(\n",
        "    torch.nn.Linear(in_features=768, out_features=128),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Dropout(p = 0.3),\n",
        "    torch.nn.Linear(in_features = 128, out_features = 32),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Dropout(p = 0.3),\n",
        "    torch.nn.Linear(in_features = 32, out_features = 3)\n",
        ")"
      ],
      "metadata": {
        "id": "md9-cdC2ZLBk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(vit_model,\n",
        "        input_size = (32, 3, 224, 224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width = 17)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmJ4a6BAZuVB",
        "outputId": "bfaa33c4-1c45-4801-e1a9-73ee3b460082"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================================================================\n",
              "Layer (type:depth-idx)                        Input Shape       Output Shape      Param #           Trainable\n",
              "=================================================================================================================\n",
              "VisionTransformer                             [32, 3, 224, 224] [32, 3]           768               Partial\n",
              "├─Conv2d: 1-1                                 [32, 3, 224, 224] [32, 768, 14, 14] (590,592)         False\n",
              "├─Encoder: 1-2                                [32, 197, 768]    [32, 197, 768]    151,296           False\n",
              "│    └─Dropout: 2-1                           [32, 197, 768]    [32, 197, 768]    --                --\n",
              "│    └─Sequential: 2-2                        [32, 197, 768]    [32, 197, 768]    --                False\n",
              "│    │    └─EncoderBlock: 3-1                 [32, 197, 768]    [32, 197, 768]    (7,087,872)       False\n",
              "│    │    └─EncoderBlock: 3-2                 [32, 197, 768]    [32, 197, 768]    (7,087,872)       False\n",
              "│    │    └─EncoderBlock: 3-3                 [32, 197, 768]    [32, 197, 768]    (7,087,872)       False\n",
              "│    │    └─EncoderBlock: 3-4                 [32, 197, 768]    [32, 197, 768]    (7,087,872)       False\n",
              "│    │    └─EncoderBlock: 3-5                 [32, 197, 768]    [32, 197, 768]    (7,087,872)       False\n",
              "│    │    └─EncoderBlock: 3-6                 [32, 197, 768]    [32, 197, 768]    (7,087,872)       False\n",
              "│    │    └─EncoderBlock: 3-7                 [32, 197, 768]    [32, 197, 768]    (7,087,872)       False\n",
              "│    │    └─EncoderBlock: 3-8                 [32, 197, 768]    [32, 197, 768]    (7,087,872)       False\n",
              "│    │    └─EncoderBlock: 3-9                 [32, 197, 768]    [32, 197, 768]    (7,087,872)       False\n",
              "│    │    └─EncoderBlock: 3-10                [32, 197, 768]    [32, 197, 768]    (7,087,872)       False\n",
              "│    │    └─EncoderBlock: 3-11                [32, 197, 768]    [32, 197, 768]    (7,087,872)       False\n",
              "│    │    └─EncoderBlock: 3-12                [32, 197, 768]    [32, 197, 768]    (7,087,872)       False\n",
              "│    └─LayerNorm: 2-3                         [32, 197, 768]    [32, 197, 768]    (1,536)           False\n",
              "├─Sequential: 1-3                             [32, 768]         [32, 3]           --                True\n",
              "│    └─Linear: 2-4                            [32, 768]         [32, 128]         98,432            True\n",
              "│    └─ReLU: 2-5                              [32, 128]         [32, 128]         --                --\n",
              "│    └─Dropout: 2-6                           [32, 128]         [32, 128]         --                --\n",
              "│    └─Linear: 2-7                            [32, 128]         [32, 32]          4,128             True\n",
              "│    └─ReLU: 2-8                              [32, 32]          [32, 32]          --                --\n",
              "│    └─Dropout: 2-9                           [32, 32]          [32, 32]          --                --\n",
              "│    └─Linear: 2-10                           [32, 32]          [32, 3]           99                True\n",
              "=================================================================================================================\n",
              "Total params: 85,901,315\n",
              "Trainable params: 102,659\n",
              "Non-trainable params: 85,798,656\n",
              "Total mult-adds (G): 5.52\n",
              "=================================================================================================================\n",
              "Input size (MB): 19.27\n",
              "Forward/backward pass size (MB): 3330.78\n",
              "Params size (MB): 229.60\n",
              "Estimated Total Size (MB): 3579.65\n",
              "================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# temp"
      ],
      "metadata": {
        "id": "5PSes7sFWfIm"
      }
    }
  ]
}